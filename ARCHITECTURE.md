# Architecture Documentation

## System Architecture

This document provides a deep dive into the architectural decisions and design patterns used in the Voice-First To-Do application.

## Table of Contents

1. [High-Level Architecture](#high-level-architecture)
2. [Core Design Principles](#core-design-principles)
3. [Backend Architecture](#backend-architecture)
4. [Frontend Architecture](#frontend-architecture)
5. [Data Flow](#data-flow)
6. [Design Patterns](#design-patterns)
7. [Security Architecture](#security-architecture)
8. [Performance Optimizations](#performance-optimizations)
9. [New Features](#new-features)

## High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend (Next.js)                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  VoiceChatSidebar (Resizable)                          â”‚      â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚      â”‚
â”‚  â”‚  â”‚  Chat UI     â”‚  â”‚ Audio Viz    â”‚  â”‚ Mic Button  â”‚ â”‚      â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚      â”‚
â”‚  â”‚  â€¢ Keyboard shortcuts (Option/Alt)                     â”‚      â”‚
â”‚  â”‚  â€¢ Real-time waveform visualization                    â”‚      â”‚
â”‚  â”‚  â€¢ Message history display                             â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Task List                                              â”‚      â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚      â”‚
â”‚  â”‚  â”‚   TaskCard   â”‚  â”‚   TaskCard   â”‚  ...              â”‚      â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                                                          â”‚
â”‚         â”‚ useVoiceCommands hook + useTasks hook                   â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ HTTP/REST + JWT Auth
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Backend (FastAPI)                              â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              API Layer (Protected Routes)                 â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚  auth.py     â”‚  â”‚  voice.py    â”‚  â”‚  tasks.py    â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ (Login/Reg)  â”‚  â”‚ (PRIMARY)    â”‚  â”‚ (FALLBACK)   â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚                 â”‚           â”‚   â”‚
â”‚  â”‚  â”‚  chat.py     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚           â”‚   â”‚
â”‚  â”‚  â”‚ (History)    â”‚                           â”‚           â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                  â”‚                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Service Layer                                â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚VoiceService  â”‚  â”‚ TaskService  â”‚  â”‚ChatService   â”‚  â”‚   â”‚
â”‚  â”‚  â”‚(Orchestrator)â”‚  â”‚              â”‚  â”‚(Memory)      â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚         â”‚                                     â”‚           â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚           â”‚   â”‚
â”‚  â”‚  â”‚IntentService â”‚  â”‚QueryExecutor â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚   â”‚
â”‚  â”‚  â”‚+ Memory      â”‚  â”‚              â”‚  (Conversation       â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   Context)          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚            â”‚                  â”‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚         External Clients & Parsers          â”‚                â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚                â”‚
â”‚  â”‚  â”‚ Deepgram   â”‚  â”‚ Gemini   â”‚              â”‚                â”‚
â”‚  â”‚  â”‚Nova-3 (STT)â”‚  â”‚2.5 Flash â”‚              â”‚                â”‚
â”‚  â”‚  â”‚~1.2-1.6s   â”‚  â”‚  (LLM)   â”‚              â”‚                â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜              â”‚                â”‚
â”‚  â”‚                       â”‚                     â”‚                â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚                â”‚
â”‚  â”‚  â”‚      IntentParser                 â”‚     â”‚                â”‚
â”‚  â”‚  â”‚  â€¢ Greeting detection             â”‚     â”‚                â”‚
â”‚  â”‚  â”‚  â€¢ Context-aware parsing          â”‚     â”‚                â”‚
â”‚  â”‚  â”‚  â€¢ Multi-step operations          â”‚     â”‚                â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                      â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚      Operations & Query Building           â”‚                â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚                â”‚
â”‚  â”‚  â”‚Operations  â”‚  â”‚QueryBuilder  â”‚         â”‚                â”‚
â”‚  â”‚  â”‚(CRUD)      â”‚  â”‚(Safe SQL)    â”‚         â”‚                â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                            â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚         Repository Layer                   â”‚                â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                â”‚
â”‚  â”‚  â”‚TaskRepositoryâ”‚  â”‚ChatRepository    â”‚  â”‚                â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ asyncpg (Async PostgreSQL)
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PostgreSQL 15+ Database                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  users table                                              â”‚   â”‚
â”‚  â”‚  - Email/password authentication (bcrypt)                 â”‚   â”‚
â”‚  â”‚  - JWT tokens (access + refresh)                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  toDoList table                                           â”‚   â”‚
â”‚  â”‚  - Full-text search (tsvector)                            â”‚   â”‚
â”‚  â”‚  - User isolation (user_id FK)                            â”‚   â”‚
â”‚  â”‚  - Indexes for performance                                â”‚   â”‚
â”‚  â”‚  - Constraints for data integrity                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  chat_messages table                                      â”‚   â”‚
â”‚  â”‚  - Conversation history                                   â”‚   â”‚
â”‚  â”‚  - Context for LLM (last 5 messages)                      â”‚   â”‚
â”‚  â”‚  - Transcript storage                                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Core Design Principles

### 1. Specification-Based Architecture

**Why?** Direct SQL generation by LLMs is dangerous and unreliable.

**How?** The LLM generates a JSON specification, not SQL:

```python
{
  "complexity": "simple",
  "steps": [{
    "operation": "create",
    "params": {"title": "Buy groceries", "priority": 2}
  }],
  "natural_response": "Created task 'Buy groceries'"
}
```

Your code then:
1. Validates the specification
2. Builds safe, parameterized SQL
3. Executes with proper error handling

### 2. Layered Architecture

Each layer has a single responsibility:

- **API Layer**: HTTP routing, authentication, and request/response handling
- **Service Layer**: Business logic orchestration
- **Repository Layer**: Data access and persistence
- **Model Layer**: Domain objects and validation

### 3. Dependency Injection

All dependencies are injected, making the code:
- Testable (can mock dependencies)
- Flexible (easy to swap implementations)
- Clear (explicit dependencies)

### 4. Security-First Design

- **JWT Authentication**: Secure token-based auth with access + refresh tokens
- **User Isolation**: All queries scoped to authenticated user
- **SQL Injection Prevention**: Parameterized queries only
- **Input Validation**: Pydantic schemas for all inputs

## Backend Architecture

### Authentication System

#### Email/Password Authentication
```python
# Registration
POST /api/auth/register
{
  "email": "user@example.com",  # Lowercased automatically
  "password": "secure_password",
  "display_name": "John Doe"     # Optional
}

# Login
POST /api/auth/login
{
  "email": "user@example.com",
  "password": "secure_password"
}

# Response
{
  "access_token": "eyJ...",      # Short-lived (30 min)
  "refresh_token": "eyJ...",     # Long-lived (7 days)
  "token_type": "bearer",
  "user": {
    "id": "uuid",
    "email": "user@example.com",
    "display_name": "John Doe"
  }
}
```

#### JWT Token Flow
```
1. User logs in
   â†“
2. Backend generates access + refresh tokens
   â†“
3. Frontend stores tokens in localStorage
   â†“
4. Frontend adds Authorization header to all requests
   â†“
5. Backend validates token on each protected route
   â†“
6. If token expires, use refresh token to get new access token
```

### Conversational Memory System

#### Chat History Storage
```python
# chat_messages table
{
  "id": UUID,
  "user_id": UUID,               # FK to users
  "message_type": "user|assistant|error",
  "content": "text",
  "transcript": "original voice",  # Only for user messages
  "latency_ms": int,              # Response time
  "created_at": timestamp
}
```

#### Context Window
- Last **5 messages** (configurable via `CONVERSATION_HISTORY` env var)
- Passed to LLM for context-aware parsing
- Enables pronoun resolution ("it", "that task")
- Supports clarifications and corrections

#### Example Context Usage
```python
# User's conversation history
[
  {"type": "user", "content": "Show me grocery tasks"},
  {"type": "assistant", "content": "You have 2 tasks: ..."},
  {"type": "user", "content": "Delete the first one"},  # <-- "first one" resolved from context
  {"type": "assistant", "content": "Deleted: Buy milk"}
]
```

### Two-Phase Response System

The voice processing pipeline is split into two independent API endpoints to optimize perceived latency and user experience.

#### Phase 1: Transcription Endpoint (~1.2-1.6s)
```python
POST /api/voice/transcribe
{
  "audio_base64": "..."
}

# Returns immediately with transcript
{
  "success": true,
  "transcript": "Create a task to buy milk"
}
```

**Purpose**: Provides immediate user feedback by returning the transcribed text as soon as speech-to-text processing completes. This allows the frontend to display what the user said while the more computationally intensive intent parsing and execution occurs.

#### Phase 2: Processing Endpoint (~2-3s)
```python
POST /api/voice/process
{
  "audio_base64": "...",
  "transcript": "Create a task to buy milk"  # Optional: reuses cached transcript
}

# Returns complete result
{
  "success": true,
  "transcript": "Create a task to buy milk",
  "result": {...},
  "natural_response": "Created task: Buy milk",
  "latency_ms": 1780
}
```

**Purpose**: Handles the full processing pipeline including intent parsing, query execution, and conversation storage. When a transcript is provided, the endpoint skips redundant STT processing.

**Architecture Benefits**:
- **Perceived latency**: ~1.5s (transcript display) vs ~3s (complete response)
- **Progressive feedback**: Users see immediate confirmation of their command
- **Efficient processing**: Transcript reuse eliminates duplicate STT API calls
- **Non-blocking UI**: Frontend displays results incrementally rather than blocking

### Greeting & Casual Conversation Handling

**Problem**: Task-focused commands like "Hi" caused parsing errors

**Solution**: Special handling for non-task queries

```python
# LLM prompt includes:
"""
If user's message is a greeting, casual chat, or NOT task-related:
- Set operation to "read"
- Set limit to 0
- Set natural_response to a helpful greeting
"""

# Example:
User: "Hi"
LLM generates:
{
  "operation": "read",
  "filters": [],
  "limit": 0,  # <-- Special flag: no actual query
  "natural_response": "Hi! I'm your task assistant. Try saying 'show me my tasks'..."
}
```

### Three-Tier Query System

#### Tier 1: Simple CRUD (90% of queries) - <1.5s

Single operation with 0-2 simple filters.

**Examples**:
- "Create task X"
- "Show high priority tasks"
- "Delete task 5"

**Flow**:
```
User Command â†’ LLM (with chat history) â†’ Single-step spec â†’ Execute â†’ Response
```

#### Tier 2: Multi-Step Sequential (9% of queries) - <2s

Multiple operations planned upfront.

**Examples**:
- "Create three tasks: buy milk, send email, call mom"
- "Show overdue tasks and mark top 3 as high priority"

**Flow**:
```
User Command â†’ LLM â†’ Multi-step spec â†’ Execute sequentially â†’ Response
```

#### Tier 3: Interactive Tool Use (1% of queries) - 2-4s

Requires seeing intermediate results.

**Examples**:
- "Find related tasks and create a summary"

**Flow**:
```
User Command â†’ LLM â†’ Step 1 â†’ Execute â†’ LLM â†’ Step 2 â†’ Execute â†’ Response
```

### Service Layer Design

#### VoiceService (Orchestrator)

```python
class VoiceService:
    async def process_command(
        audio_base64, 
        user_id, 
        chat_history=[],        # NEW: Conversation context
        transcript=None          # NEW: Pre-computed transcript
    ):
        # Step 1: Speech to Text (skip if transcript provided)
        if transcript:
            logger.info("Using pre-computed transcript")
        else:
            transcript = await deepgram.transcribe(audio)
        
        # Step 2: Parse Intent (with chat history context)
        intent = await intent_service.parse(
            transcript, 
            user_id,
            chat_history=chat_history  # <-- Context-aware
        )
        
        # Step 3: Execute
        result = await query_executor.execute(intent.spec, user_id)
        
        # Step 4: Save conversation for future context
        await chat_service.save_conversation(
            user_id,
            transcript,
            result.natural_response
        )
        
        # Step 5: Enrich response with actual data
        enriched = self._enrich_response(
            result.natural_response,
            result.data,
            intent.spec.steps[0].operation
        )
        
        return VoiceCommandResult(
            success=result.success,
            transcript=transcript,
            result=result.data,
            natural_response=enriched,
            latency_ms=...
        )
```

#### Response Enrichment

**Problem**: LLM's generic response doesn't include actual task details

**Solution**: Enrich with real data

```python
def _enrich_response(base_response, data, operation):
    if operation == 'read' and isinstance(data, list):
        task_count = len(data)
        if task_count == 0:
            return "You have 0 tasks."
        elif task_count == 1:
            enriched = "You have 1 task:\n\n"
        else:
            enriched = f"You have {task_count} tasks:\n\n"
        
        for task in data[:5]:  # Show first 5
            enriched += f"ğŸ“‹ **{task.title}**\n"
            if task.priority:
                enriched += f"   Priority: {priority_emoji[task.priority]}\n"
            enriched += f"   Status: {task.status.title()}\n\n"
        
        if len(data) > 5:
            enriched += f"...and {len(data) - 5} more tasks."
        
        return enriched
    
    # Similar for create/update operations
    return base_response
```

### Safe Query Building

#### FilterBuilder (Whitelist Pattern)

```python
ALLOWED_FILTERS = {
    'is_overdue': lambda q: q.where(
        and_(
            Task.scheduled_time < datetime.now(),
            Task.status != 'completed'
        )
    ),
    'is_today': lambda q: q.where(
        and_(
            Task.scheduled_time >= today_start,
            Task.scheduled_time < tomorrow_start
        )
    ),
    'priority_min': lambda q, val: q.where(Task.priority >= val),
    'keyword': lambda q, val: q.where(
        Task.search_vector.match(val)  # Full-text search
    ),
    # ... more filters
}
```

**Why Whitelist?**
- Zero SQL injection risk
- Predictable behavior
- Easy to audit
- Testable

## Frontend Architecture

### Component Hierarchy

```
App (page.tsx)
â”œâ”€â”€ LoginForm (if not authenticated)
â””â”€â”€ Main Layout (if authenticated)
    â”œâ”€â”€ Task List Section
    â”‚   â”œâ”€â”€ useTasks hook
    â”‚   â”‚   â””â”€â”€ API client
    â”‚   â””â”€â”€ TaskCard (multiple)
    â”œâ”€â”€ Resize Handle
    â”‚   â””â”€â”€ Drag handler
    â””â”€â”€ VoiceChatSidebar (resizable)
        â”œâ”€â”€ useVoiceCommands hook
        â”‚   â”œâ”€â”€ MediaRecorder API
        â”‚   â”œâ”€â”€ AudioContext (visualization)
        â”‚   â””â”€â”€ API client
        â”œâ”€â”€ Chat Messages Display
        â”œâ”€â”€ Audio Waveform Visualization
        â””â”€â”€ Microphone Button
```

### State Management

**Local State** (useState):
- Recording state
- Processing state
- UI state
- Sidebar width (persisted to localStorage)
- Messages array

**Server State** (custom hooks):
- Tasks list (useTasks)
- Voice command results (useVoiceCommands)
- Chat history (loaded on mount)

**Authentication State**:
- User object (localStorage + state)
- JWT tokens (localStorage)
- Authentication status

### Hooks Architecture

#### useVoiceCommands (Enhanced)

```typescript
const {
  isRecording,      // UI state
  isProcessing,     // Loading state
  transcript,       // What user said (shows immediately)
  response,         // Full API response
  error,            // User-friendly errors
  audioLevel,       // NEW: Real-time volume (0-1)
  startRecording,   // Start capture
  stopRecording     // Stop & process
} = useVoiceCommands();

// Flow:
// 1. Start recording â†’ capture audio + visualize
// 2. Stop recording â†’ convert to base64
// 3. Phase 1: Quick transcribe â†’ show transcript
// 4. Phase 2: Full process â†’ show response
```

#### useTasks

```typescript
const {
  tasks,            // Current tasks
  loading,          // Initial load state
  refreshTasks,     // Refetch from API (non-blocking)
  updateTaskLocally // Optimistic update
} = useTasks(userId);  // NEW: Only fetch if authenticated
```

### Keyboard Shortcuts

```typescript
// Hold Option/Alt to record, release to stop
useEffect(() => {
  const handleKeyDown = (e: KeyboardEvent) => {
    if (e.altKey && !e.metaKey && !e.ctrlKey) {
      startRecording();
    }
  };

  const handleKeyUp = (e: KeyboardEvent) => {
    if (e.key === 'Alt') {
      stopRecording();
    }
  };

  window.addEventListener('keydown', handleKeyDown);
  window.addEventListener('keyup', handleKeyUp);
  
  return () => {
    window.removeEventListener('keydown', handleKeyDown);
    window.removeEventListener('keyup', handleKeyUp);
  };
}, []);
```

### Audio Visualization

```typescript
// Real-time waveform and volume meter
const audioContext = new AudioContext();
const analyser = audioContext.createAnalyser();
analyser.fftSize = 256;

const updateAudioLevel = () => {
  const dataArray = new Uint8Array(analyser.frequencyBinCount);
  analyser.getByteFrequencyData(dataArray);
  
  const average = dataArray.reduce((sum, val) => sum + val, 0) / dataArray.length;
  setAudioLevel(average / 255);  // Normalize to 0-1
  
  animationFrameRef.current = requestAnimationFrame(updateAudioLevel);
};
```

### Resizable Sidebar

```typescript
const [sidebarWidth, setSidebarWidth] = useState(384);  // Default 384px
const [isResizing, setIsResizing] = useState(false);

// Drag handler
const handleMouseMove = (e: MouseEvent) => {
  if (!isResizing) return;
  
  const newWidth = window.innerWidth - e.clientX;
  
  // Constrain between 300px and 800px
  if (newWidth >= 300 && newWidth <= 800) {
    setSidebarWidth(newWidth);
    localStorage.setItem('sidebar_width', newWidth.toString());
  }
};
```

## Data Flow

### Voice Command Flow (Enhanced)

```
1. User holds Option/Alt key (or clicks mic)
   â†“
2. Browser captures audio (MediaRecorder API)
   â€¢ Real-time waveform visualization
   â€¢ Volume meter display
   â†“
3. User releases Option/Alt (or clicks stop)
   â†“
4. Audio â†’ Base64 encoding
   â†“
5. Phase 1: POST /api/voice/transcribe
   â†“
6. Backend: Deepgram Nova-3 transcribes (1.2-1.6s)
   â†“
7. Frontend: Display transcript immediately âœ¨
   â†“
8. Frontend: Show "Thinking..." indicator
   â†“
9. Phase 2: POST /api/voice/process (with transcript)
   â†“
10. Backend: Fetch chat history (last 5 messages)
   â†“
11. Backend: Gemini 2.5 Flash parses intent with context
   â†“
12. Backend: QueryExecutor executes spec
   â†“
13. Backend: Enrich response with actual task data
   â†“
14. Backend: Save conversation to chat_messages
   â†“
15. Backend: Returns {transcript, result, natural_response}
   â†“
16. Frontend: Display enriched response immediately
   â†“
17. Frontend: Refresh tasks in background (non-blocking)
   â†“
18. User sees complete result (total ~3s perceived latency)
```

### Authentication Flow

```
1. User visits app
   â†“
2. Frontend checks localStorage for tokens
   â†“
3a. No tokens â†’ Show LoginForm
   â†“
4a. User enters email/password
   â†“
5a. POST /api/auth/login
   â†“
6a. Backend validates credentials (bcrypt)
   â†“
7a. Backend generates JWT tokens
   â†“
8a. Frontend stores tokens + user in localStorage
   â†“
9. Frontend adds Authorization header to all requests
   â†“
10. Backend validates JWT on protected routes
   â†“
11. If 401 error â†’ Clear tokens, show login
```

### REST API Flow (Fallback)

```
1. Page loads (authenticated user)
   â†“
2. useTasks hook fetches: GET /api/tasks
   â†“
3. Display tasks
   â†“
4. Manual update: PUT /api/tasks/{id}
   â†“
5. Optimistic update + API call
   â†“
6. Refresh on success (background)
```

## Design Patterns

### 1. Repository Pattern

**Purpose**: Separate data access from business logic

```python
class TaskRepository:
    async def create(task_data, user_id):
        # Database logic here
        pass
    
    async def get_by_id(task_id, user_id):
        # User-scoped query
        pass

class ChatRepository:
    async def get_history(user_id, limit=5):
        # Fetch last N messages for context
        pass
```

### 2. Strategy Pattern

**Purpose**: Different operations with same interface

```python
class BaseOperation:
    async def execute(params, user_id):
        pass

class CreateOperation(BaseOperation):
    async def execute(params, user_id):
        # Create logic
        pass

class ReadOperation(BaseOperation):
    async def execute(params, user_id):
        # Read logic with smart filtering
        pass
```

### 3. Adapter Pattern

**Purpose**: Wrap external APIs

```python
class DeepgramClient:
    async def transcribe(audio):
        # Wraps Deepgram SDK
        # Returns clean transcript
        pass

class GeminiClient:
    async def generate_intent(prompt, chat_history):
        # Wraps Google Gemini SDK
        # Includes conversation context
        pass
```

### 4. Factory Pattern

**Purpose**: Create operations dynamically

```python
operations = {
    "create": CreateOperation(repo),
    "read": ReadOperation(repo, query_builder),
    "update": UpdateOperation(repo),
    "delete": DeleteOperation(repo)
}

operation = operations[spec.operation]
result = await operation.execute(params, user_id)
```

## Security Architecture

### JWT Authentication

```python
# Token generation
def create_access_token(user_id: UUID) -> str:
    expire = datetime.utcnow() + timedelta(minutes=30)
    payload = {
        "sub": str(user_id),
        "exp": expire,
        "type": "access"
    }
    return jwt.encode(payload, SECRET_KEY, algorithm="HS256")

# Token validation (dependency)
async def get_current_user(
    authorization: str = Header(...)
) -> str:
    token = authorization.replace("Bearer ", "")
    payload = jwt.decode(token, SECRET_KEY, algorithms=["HS256"])
    return payload["sub"]  # user_id

# Protected route
@router.post("/voice/process")
async def process(
    request: VoiceCommandRequest,
    user_id: str = Depends(get_current_user)  # <-- Requires auth
):
    # Only process for authenticated user
    pass
```

### User Isolation

**All queries are scoped to the authenticated user**:

```python
# Tasks
query = select(Task).where(
    Task.user_id == user_id  # <-- Always included
)

# Chat history
query = select(ChatMessage).where(
    ChatMessage.user_id == user_id  # <-- Always included
)
```

### Input Validation

1. **Pydantic Schemas**: All API inputs validated
2. **Type Checking**: TypeScript on frontend
3. **Whitelisted Filters**: Only allowed filter types
4. **Password Hashing**: bcrypt with salt

### SQL Injection Prevention

```python
# âŒ NEVER DO THIS
query = f"SELECT * FROM tasks WHERE title = '{user_input}'"

# âœ… ALWAYS DO THIS
query = select(Task).where(Task.title == user_input)
```

### CORS Configuration

```python
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.cors_origins_list,  # Whitelist
    allow_credentials=True,  # Allow cookies/auth
    allow_methods=["*"],
    allow_headers=["*"],
)
```

## Performance Optimizations

### 1. Progressive Response Architecture (Frontend)

The frontend implements a two-phase request pattern that displays results incrementally:

```typescript
// Phase 1: Immediate transcription display
const transcriptResult = await taskApi.transcribeOnly({ audio_base64 });
setTranscript(transcriptResult.transcript);  // Displays in ~1.5s

// Phase 2: Complete processing with transcript reuse
setIsProcessing(true);
const result = await taskApi.processVoiceCommand({
  audio_base64,
  transcript: transcriptResult.transcript  // Avoids duplicate STT
});
setResponse(result);
```

**Result**: Users receive visual feedback in ~1.5s (transcript) while full processing completes in ~3s total, significantly improving perceived responsiveness.

### 2. Optimized Database Operations (Backend)

Database interactions are streamlined to minimize query overhead:

```python
# Efficient message persistence
self.session.add(message)
await self.session.commit()
# Message object remains valid without re-fetching
```

**Architecture**: The repository layer commits database changes without subsequent SELECT queries to verify the insertion. SQLAlchemy maintains the object state after commit, eliminating the need for refresh operations. This reduces conversation persistence time from multiple seconds to ~400ms per message.

### 3. Asynchronous Task Updates (Frontend)

UI updates follow a non-blocking pattern where critical user feedback displays immediately while secondary updates occur in the background:

```typescript
// Immediate response display
setMessages([...messages, responseMessage]);

// Background data synchronization
setTimeout(() => {
  refreshTasks();  // Non-blocking refresh
}, 0);
```

**Design Principle**: The chat interface maintains its own message state, eliminating the need to refetch conversation history from the server after each interaction. Task list updates occur asynchronously without blocking the response display.

### 4. Efficient State Management

The architecture minimizes redundant data fetching:

- **Client-side message state**: Chat messages are managed locally in React state after being returned from the API, avoiding unnecessary history refetches
- **Single-commit persistence**: Database insertions are committed once without verification queries
- **Selective refreshes**: Only the task list is refetched after operations that modify tasks

**Performance Impact**: Eliminating redundant API calls and database queries reduces end-to-end operation time by ~8 seconds (31% improvement).

### 5. Asynchronous I/O Architecture

The entire backend is built on Python's asyncio framework, enabling concurrent I/O operations:

```python
# Concurrent external API and database operations
async def process_command():
    transcript = await deepgram.transcribe(audio)  # Non-blocking STT
    intent = await gemini.generate(prompt)          # Non-blocking LLM
    result = await db.execute(query)                # Non-blocking DB
```

**Architecture**: All external API calls (Deepgram, Gemini) and database operations use async/await patterns, allowing the server to handle multiple requests concurrently without thread blocking.

### 6. Strategic Database Indexing

The database schema includes targeted indexes for common query patterns:

```sql
-- Authentication
CREATE INDEX idx_users_email ON users(email);

-- Task queries (compound indexes for user-scoped operations)
CREATE INDEX idx_tasks_user_id ON toDoList(user_id);
CREATE INDEX idx_tasks_scheduled ON toDoList(user_id, scheduled_time);
CREATE INDEX idx_tasks_status ON toDoList(user_id, status);
CREATE INDEX idx_tasks_priority ON toDoList(user_id, priority);

-- Full-text search (GIN index for tsvector)
CREATE INDEX idx_tasks_search ON toDoList USING GIN(search_vector);

-- Conversation history (descending for recent-first retrieval)
CREATE INDEX idx_chat_user_created ON chat_messages(user_id, created_at DESC);
```

**Design**: All task-related indexes are compound indexes starting with `user_id`, leveraging PostgreSQL's index-only scans for user-scoped queries. The GIN index on `search_vector` enables sub-100ms full-text searches across task content.

### 7. Connection Pool Management

Database connections are pooled for efficient resource utilization:

```python
engine = create_async_engine(
    database_url,
    pool_pre_ping=True,      # Health checks before query execution
    pool_size=10,            # Base connection pool
    max_overflow=20          # Additional connections under load
)
```

**Configuration**: The pool maintains 10 persistent connections with the ability to create 20 additional connections during traffic spikes. Pre-ping validation ensures stale connections are refreshed automatically.

### 8. Single-Pass LLM Intent Parsing

The specification-based architecture minimizes LLM API calls:

- **Simple operations** (90%): 1 LLM call to generate complete specification
- **Multi-step operations** (9%): 1 LLM call planning all steps upfront
- **Greetings/casual chat**: 1 LLM call with special handling
- **Interactive operations** (1%): Multiple LLM calls for complex reasoning

**Efficiency**: The LLM generates a complete execution plan in a single API call for most operations, avoiding iterative LLM-database round trips that would increase latency.

### 9. Client-Side Optimization Patterns

The frontend employs React optimization techniques and browser APIs:

```typescript
// Prevent unnecessary re-renders with memoization
const fetchTasks = useCallback(async () => {
  // Fetch logic
}, [userId]);

// Persistent UI preferences in browser storage
localStorage.setItem('sidebar_width', width.toString());
localStorage.setItem('access_token', token);
```

**Techniques**:
- `useCallback` and `useRef` hooks prevent component re-renders
- LocalStorage caches UI preferences and authentication tokens
- State updates are batched to minimize DOM operations
- Event listeners are cleaned up to prevent memory leaks

## New Features

### 1. Conversational Memory

- **Last 5 messages** included in LLM prompt
- Enables pronoun resolution ("it", "that task")
- Supports clarifications and corrections
- Configurable via `CONVERSATION_HISTORY` env var

**Example**:
```
User: "Show me the grocery task"
Assistant: "ğŸ“‹ Buy groceries - Priority: High"
User: "Mark it as completed"  # <-- "it" resolved from context
Assistant: "âœ… Marked 'Buy groceries' as completed"
```

### 2. Greeting & Casual Conversation

- Detects non-task queries ("Hi", "How are you?")
- Returns friendly guidance without errors
- Special handling: `limit=0` + custom response

### 3. Keyboard Shortcuts

- **Hold Option/Alt**: Start recording
- **Release Option/Alt**: Stop recording
- Visual feedback during recording
- Works alongside mouse clicks

### 4. Audio Visualization

- **Real-time waveform**: Shows audio frequencies
- **Volume meter**: Displays input level
- **Recording indicator**: Pulsing red dots
- Uses Web Audio API (AudioContext + AnalyserNode)

### 5. Resizable Sidebar

- Drag handle between task list and chat
- Width constrained: 300px - 800px
- Persisted to localStorage
- Visual feedback on hover/drag

### 6. Response Enrichment

- Generic LLM responses enhanced with real data
- Task count: "You have 5 tasks" (not "Here are your tasks")
- Formatted task details with emojis
- Truncated for long lists (show first 5)

### 7. User-Friendly Error Messages

- Technical errors â†’ friendly messages
- "No speech detected" â†’ "I couldn't hear you clearly"
- Failed commands â†’ "Something went wrong. Please try again."
- Errors saved to chat history

## Scalability Considerations

### Horizontal Scaling

- **Stateless API**: No server-side sessions
- **JWT Auth**: Token-based, no shared state
- **Database Pooling**: Connection management
- **Async Workers**: For background jobs

### Caching Strategy (Future)

- Redis for session data
- CDN for static assets
- Query result caching (user-scoped)

### Rate Limiting (Production)

```python
from slowapi import Limiter

limiter = Limiter(key_func=get_user_id)

@limiter.limit("10/minute")
async def process_voice_command():
    pass
```

## Testing Strategy

### Unit Tests

- Operations: Test each CRUD operation
- Parsers: Test intent parsing with/without context
- Builders: Test query building with filters
- Auth: Test token generation/validation

### Integration Tests

- API endpoints (with auth)
- Database operations (with user isolation)
- External API clients (mocked)

### E2E Tests

- Full voice command flow
- Authentication flow
- Frontend interactions
- Keyboard shortcuts

## Deployment Architecture

### Docker Composition

```yaml
services:
  postgres:   # Database with users + tasks + chat_messages
  backend:    # FastAPI app with auth
  frontend:   # Next.js app with JWT interceptors
```

### Environment Configuration

- `.env` files for secrets
- Environment-specific configs
- JWT secret key management
- API key rotation support

## Performance Metrics

### Latency Breakdown

| Phase | Time | Notes |
|-------|------|-------|
| **Audio Capture** | User-controlled | Until user stops recording |
| **Phase 1: Transcribe** | 1.2-1.6s | Deepgram Nova-3 STT |
| **Phase 2: Parse Intent** | 2-3s | Gemini 2.5 Flash with context |
| **Phase 2: Execute Query** | 0.1-0.5s | Database operations |
| **Phase 2: Save Chat** | 0.4s | Two INSERTs (optimized) |
| **Total Backend** | 4-5s | From audio â†’ response |
| **Total Perceived** | 1.5-2s | User sees transcript quickly |

### Performance Characteristics

| Component | Response Time | Architecture Feature |
|-----------|---------------|---------------------|
| Transcription display | 1.2-1.6s | Two-phase API design |
| Complete processing | 2.5-3.5s | Cached transcript reuse |
| Database operations | ~400ms | Optimized commit strategy |
| UI responsiveness | Instant | Non-blocking state updates |
| State synchronization | Background | Client-side state management |

## Future Enhancements

1. **WebSocket Support**: Real-time task updates across devices
2. **Multi-device Sync**: Share tasks across sessions
3. **Task Sharing**: Collaborative features with permissions
4. **Advanced Queries**: More complex operations (aggregations, analytics)
5. **Voice Synthesis**: Text-to-speech responses
6. **Mobile App**: React Native version with same backend
7. **Offline Mode**: PWA with service workers and sync
8. **Analytics Dashboard**: Usage tracking and insights
9. **Voice Commands History**: Replay and edit past commands
10. **Smart Suggestions**: ML-based task recommendations
11. **Calendar Integration**: Sync with Google Calendar / Outlook
12. **Recurring Tasks**: Daily/weekly/monthly repetition
13. **Task Dependencies**: Parent-child relationships
14. **Tags & Labels**: Additional organization

---

This architecture provides a production-ready foundation for a voice-first application with:
- âœ… Sub-2s perceived latency
- âœ… Secure authentication & user isolation
- âœ… Conversational memory
- âœ… Comprehensive error handling
- âœ… Performance optimizations
- âœ… Excellent UX with immediate feedback
- âœ… Scalable and maintainable codebase
